import streamlit as st
from ultralytics import YOLO
from PIL import Image
import numpy as np
import cv2
import tempfile

# –ó–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
st.set_page_config(
    page_title="–û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–º–∏–¥–æ—Ä–æ–≤",
    page_icon="üçÖ",
    layout="wide"
)

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ CSS —Å—Ç–∏–ª–µ–π
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        color: #ff4b4b;
        text-align: center;
    }
    .subheader {
        font-size: 1.5rem;
        color: #ff6b6b;
    }
    .stButton>button {
        background-color: #ff4b4b;
        color: white;
    }
    .stSlider>div>div>div {
        background-color: #ff4b4b;
    }
</style>
""", unsafe_allow_html=True)

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.markdown('<h1 class="main-header">üçÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–æ–º–∏–¥–æ—Ä–æ–≤</h1>', unsafe_allow_html=True)
st.markdown("### –û–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ –ø–æ–¥—Å—á–µ—Ç –ø–æ–º–∏–¥–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ YOLO")

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    try:
        model = YOLO("./best.pt")
        return model
    except:
        st.error("–§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É –º–æ–¥–µ–ª–∏.")
        return None

model = load_model()

# –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏
st.sidebar.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
conf_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ –¥–æ–≤–µ—Ä–∏—è", 0.0, 1.0, 0.5, 0.01)
iou_threshold = st.sidebar.slider("–ü–æ—Ä–æ–≥ IOU", 0.0, 1.0, 0.6, 0.01)

# –û—Å–Ω–æ–≤–Ω–æ–π –∫–æ–Ω—Ç–µ–Ω—Ç ‚Äî –≤–∫–ª–∞–¥–∫–∏
tab1, tab2 = st.tabs(["üì∑ –ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", "üé• –ó–∞–≥—Ä—É–∑–∏—Ç—å –≤–∏–¥–µ–æ"])

with tab1:
    uploaded_image = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø–æ–º–∏–¥–æ—Ä–æ–≤", type=['jpg', 'jpeg', 'png'])
    
    if uploaded_image is not None and model is not None:
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image = Image.open(uploaded_image)
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_column_width=True)
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏
        with st.spinner("–ú–æ–¥–µ–ª—å –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ..."):
            results = model.predict(np.array(image), conf=conf_threshold, iou=iou_threshold)
            result = results[0]
            
            # –ü–æ–ª—É—á–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –∞–Ω–Ω–æ—Ç–∞—Ü–∏–µ–π
            annotated_image = result.plot()
            annotated_image = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)
            
            with col2:
                st.image(annotated_image, caption="–û–±–Ω–∞—Ä—É–∂–µ–Ω–Ω—ã–µ –ø–æ–º–∏–¥–æ—Ä—ã", use_column_width=True)
        
        # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        detections = len(result.boxes)
        st.success(f"‚úÖ –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ {detections} –ø–æ–º–∏–¥–æ—Ä–æ–≤!")
        
        # –ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –∫–∞–∂–¥–æ–º –æ–±—ä–µ–∫—Ç–µ
        if detections > 0:
            with st.expander("–ü–æ–¥—Ä–æ–±–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è"):
                for i, box in enumerate(result.boxes):
                    conf = box.conf[0].item()
                    cls = result.names[box.cls[0].item()]
                    st.write(f"{i+1}. {cls} - –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å: {conf:.2f}")

with tab2:
    uploaded_video = st.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∏–¥–µ–æ —Å –ø–æ–º–∏–¥–æ—Ä–∞–º–∏", type=['mp4', 'mov', 'avi'])
    
    if uploaded_video is not None and model is not None:
        # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤–∏–¥–µ–æ
        tfile = tempfile.NamedTemporaryFile(delete=False)
        tfile.write(uploaded_video.read())
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤–∏–¥–µ–æ
        st.info("–í–∏–¥–µ–æ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –Ω–µ–∫–æ—Ç–æ—Ä–æ–µ –≤—Ä–µ–º—è")
        
        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –≤–∏–¥–µ–æ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        results = model.predict(tfile.name, conf=conf_threshold, iou=iou_threshold, save=True, project=".", name="output", exist_ok=True)
        
        try:
            # –ü—É—Ç—å –∫ –ø–æ—Å–ª–µ–¥–Ω–µ–º—É –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–º—É –≤–∏–¥–µ–æ
            video_results = list(results)[0]
            output_video_path = video_results.save_dir
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤–∏–¥–µ–æ —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏
            st.success("–í–∏–¥–µ–æ —É—Å–ø–µ—à–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ!")
            st.video("output/output_video.mp4")
            
        except:
            st.error("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown("### –û –ø—Ä–æ–µ–∫—Ç–µ")
st.markdown("""
–≠—Ç–æ—Ç –ø—Ä–æ–µ–∫—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∞–Ω –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –∏ –ø–æ–¥—Å—á–µ—Ç–∞ –ø–æ–º–∏–¥–æ—Ä–æ–≤ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ YOLO.
–ò—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è —Å–ª–µ–¥—É—é—â–∏–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏:
- **YOLOv8** - –º–æ–¥–µ–ª—å –¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –æ–±—ä–µ–∫—Ç–æ–≤
- **Streamlit** - –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
- **OpenCV** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –∏ –≤–∏–¥–µ–æ
""")
